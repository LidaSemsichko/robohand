{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL INITIALIZATION\n",
    "\n",
    "model = YOLO(\"DetectionWeights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'center', 1: 'hole', 2: 'screw'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODEL LABEL CHECK\n",
    "\n",
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEBCAM CODE\n",
    "\n",
    "def check_similar(given, trial_data):\n",
    "\n",
    "    x = given[0]\n",
    "    y = given[1]\n",
    "\n",
    "    for trial in trial_data:\n",
    "\n",
    "        trial_x = trial[0]\n",
    "        trial_y = trial[1]\n",
    "\n",
    "        if abs(x - trial_x) < 150 and abs(y - trial_y) < 150:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def live_detection(src, model):\n",
    "    cap = cv2.VideoCapture(src)\n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, conf=0.65)\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        cv2.imshow(\"YOLO Inference\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def make_image(center, holes, screws, frame):\n",
    "\n",
    "    for elem in ([center], holes, screws):\n",
    "\n",
    "        color = [(0, 255, 0), (255, 0, 0), (0, 0, 255)][([center], holes, screws).index(elem)]\n",
    "\n",
    "        for data in elem:\n",
    "\n",
    "            x, y, w, h = data\n",
    "            cv2.rectangle(frame, (x - w//2, y - h//2), (x + w//2, y + h//2), color, 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def get_data(center_id, hole_id, screw_id, src, model):\n",
    "\n",
    "    cap = cv2.VideoCapture(src)\n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, conf=0.65)\n",
    "\n",
    "        center_data = None\n",
    "        hole_data = []\n",
    "        screw_data = []\n",
    "\n",
    "        for detections in results[0].boxes:\n",
    "            data = list(map(int, detections.xywh.tolist()[0]))\n",
    "            item_class = detections.cls[0].item()\n",
    "\n",
    "            if item_class == center_id:\n",
    "                center_data = data\n",
    "\n",
    "            elif item_class == hole_id:\n",
    "                hole_data.append(data)\n",
    "\n",
    "            elif item_class == screw_id:\n",
    "                screw_data.append(data)\n",
    "\n",
    "        copy_list = []\n",
    "\n",
    "        for screw in screw_data:\n",
    "            if not check_similar(screw, hole_data):\n",
    "                \n",
    "                copy_list.append(screw)\n",
    "        \n",
    "        screw_data = copy_list\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        if center_data is not None and len(hole_data) > 0 and len(screw_data) > 0:\n",
    "            img = make_image(center_data, hole_data, screw_data, frame.copy())\n",
    "            cv2.imwrite(f\"Result.jpg\", img)\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return center_data, hole_data, screw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 center, 3 holes, 3 screws, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "([250, 266, 20, 24], [[174, 308, 14, 16], [108, 239, 15, 16], [176, 241, 14, 16]], [[404, 189, 13, 15], [401, 236, 12, 15]])\n"
     ]
    }
   ],
   "source": [
    "#WEBCAM CODE\n",
    "\n",
    "print(get_data(0, 1, 2, 0, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#ESP FUNCTIONALITY CHECK\n",
    "\n",
    "cam_url = 'http://192.168.107.228/capture'\n",
    "\n",
    "response = requests.get(cam_url)\n",
    "if response.status_code == 200:\n",
    "    # Save the image as a JPEG file\n",
    "    with open(\"captured_image.jpg\", \"wb\") as img_file:\n",
    "        img_file.write(response.content)\n",
    "    print(\"Image saved successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to capture image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESP CODE\n",
    "\n",
    "def check_similar(given, trial_data):\n",
    "\n",
    "    x = given[0]\n",
    "    y = given[1]\n",
    "\n",
    "    for trial in trial_data:\n",
    "\n",
    "        trial_x = trial[0]\n",
    "        trial_y = trial[1]\n",
    "\n",
    "        if abs(x - trial_x) < 150 and abs(y - trial_y) < 150:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def fetch_image_from_esp(url):\n",
    "    response = requests.get(url)\n",
    "    img_array = np.array(bytearray(response.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, -1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def make_image(center, holes, screws, frame):\n",
    "\n",
    "    for elem in ([center], holes, screws):\n",
    "\n",
    "        color = [(0, 255, 0), (255, 0, 0), (0, 0, 255)][([center], holes, screws).index(elem)]\n",
    "\n",
    "        for data in elem:\n",
    "\n",
    "            x, y, w, h = data\n",
    "            cv2.rectangle(frame, (x - w//2, y - h//2), (x + w//2, y + h//2), color, 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def get_data(center_id, hole_id, screw_id, url, model):\n",
    "\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        frame = fetch_image_from_esp(url)\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        results = model(frame, conf=0.65)\n",
    "\n",
    "        center_data = None\n",
    "        hole_data = []\n",
    "        screw_data = []\n",
    "\n",
    "        for detections in results[0].boxes:\n",
    "            data = list(map(int, detections.xywh.tolist()[0]))\n",
    "            item_class = detections.cls[0].item()\n",
    "\n",
    "            if item_class == center_id:\n",
    "                center_data = data\n",
    "\n",
    "            elif item_class == hole_id:\n",
    "                hole_data.append(data)\n",
    "\n",
    "            elif item_class == screw_id:\n",
    "                screw_data.append(data)\n",
    "\n",
    "        copy_list = []\n",
    "\n",
    "        for screw in screw_data:\n",
    "            if not check_similar(screw, hole_data):\n",
    "                \n",
    "                copy_list.append(screw)\n",
    "        \n",
    "        screw_data = copy_list\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        if center_data is not None and len(hole_data) > 0 and len(screw_data) > 0:\n",
    "            img = make_image(center_data, hole_data, screw_data, frame.copy())\n",
    "            cv2.imwrite(f\"Result.jpg\", img)\n",
    "            cv2.destroyAllWindows()\n",
    "            return center_data, hole_data, screw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 center, 3 screws, 92.0ms\n",
      "Speed: 6.0ms preprocess, 92.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 100.4ms\n",
      "Speed: 3.0ms preprocess, 100.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 196.7ms\n",
      "Speed: 2.0ms preprocess, 196.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 132.4ms\n",
      "Speed: 4.0ms preprocess, 132.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 120.7ms\n",
      "Speed: 3.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 92.0ms\n",
      "Speed: 2.0ms preprocess, 92.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 91.5ms\n",
      "Speed: 2.0ms preprocess, 91.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 89.6ms\n",
      "Speed: 2.0ms preprocess, 89.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 screws, 98.9ms\n",
      "Speed: 2.0ms preprocess, 98.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 124.0ms\n",
      "Speed: 3.8ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 81.1ms\n",
      "Speed: 2.4ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 screw, 85.1ms\n",
      "Speed: 2.5ms preprocess, 85.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 screws, 90.0ms\n",
      "Speed: 1.9ms preprocess, 90.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 screws, 140.6ms\n",
      "Speed: 2.0ms preprocess, 140.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 screws, 124.3ms\n",
      "Speed: 3.9ms preprocess, 124.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.5ms\n",
      "Speed: 2.8ms preprocess, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 88.0ms\n",
      "Speed: 2.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 3 screws, 121.0ms\n",
      "Speed: 3.0ms preprocess, 121.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 5 screws, 86.1ms\n",
      "Speed: 2.0ms preprocess, 86.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 5 screws, 144.4ms\n",
      "Speed: 3.6ms preprocess, 144.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 139.4ms\n",
      "Speed: 3.6ms preprocess, 139.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 80.9ms\n",
      "Speed: 2.0ms preprocess, 80.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 1 screw, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 3 screws, 139.9ms\n",
      "Speed: 5.0ms preprocess, 139.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 center, 1 hole, 1 screw, 83.1ms\n",
      "Speed: 2.3ms preprocess, 83.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "([369, 286, 18, 22], [[248, 259, 12, 13]], [[509, 196, 10, 12]])\n"
     ]
    }
   ],
   "source": [
    "#ESP CODE\n",
    "\n",
    "model = YOLO(\"DetectionWeights.pt\")\n",
    "cam_url = 'http://192.168.107.228/capture'\n",
    "print(get_data(0, 1, 2, cam_url, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLIFIED VERSION\n",
    "\n",
    "\n",
    "positions = [(240, 240), (240, 270), (240, 300), (240, 330)]\n",
    "\n",
    "def check_similar(given, trial_data):\n",
    "\n",
    "    x = given[0]\n",
    "    y = given[1]\n",
    "\n",
    "    trial_x = trial_data[0]\n",
    "    trial_y = trial_data[1]\n",
    "\n",
    "    return abs(x - trial_x) < 10 and abs(y - trial_y) < 10\n",
    "\n",
    "    \n",
    "\n",
    "def fetch_image_from_esp(url):\n",
    "    response = requests.get(url)\n",
    "    img_array = np.array(bytearray(response.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, -1)\n",
    "    return img\n",
    "\n",
    "def check_screws(positions, screw_id, url, model):\n",
    "\n",
    "    for _ in range(10):\n",
    "\n",
    "        frame = fetch_image_from_esp(url)\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        results = model(frame, conf=0.65)\n",
    "\n",
    "        screw_data = []\n",
    "        result = [False, False, False, False]\n",
    "\n",
    "        for detections in results[0].boxes:\n",
    "            data = list(map(int, detections.xywh.tolist()[0]))\n",
    "            item_class = detections.cls[0].item()\n",
    "\n",
    "            if item_class == screw_id:\n",
    "                screw_data.append(data)\n",
    "\n",
    "        for ind, check in enumerate(result):\n",
    "\n",
    "            if check:\n",
    "                continue\n",
    "\n",
    "            result[ind] = any(check_similar(screw, positions[ind]) for screw in screw_data)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 center, 1 screw, 93.3ms\n",
      "Speed: 4.0ms preprocess, 93.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[459, 237, 11, 12]] (240, 240)\n",
      "[[459, 237, 11, 12]] (240, 270)\n",
      "[[459, 237, 11, 12]] (240, 300)\n",
      "[[459, 237, 11, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 2 screws, 182.7ms\n",
      "Speed: 6.8ms preprocess, 182.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 238, 11, 12], [459, 266, 9, 13]] (240, 240)\n",
      "[[455, 238, 11, 12], [459, 266, 9, 13]] (240, 270)\n",
      "[[455, 238, 11, 12], [459, 266, 9, 13]] (240, 300)\n",
      "[[455, 238, 11, 12], [459, 266, 9, 13]] (240, 330)\n",
      "\n",
      "0: 480x640 2 screws, 92.0ms\n",
      "Speed: 2.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[454, 237, 11, 12], [459, 266, 9, 12]] (240, 240)\n",
      "[[454, 237, 11, 12], [459, 266, 9, 12]] (240, 270)\n",
      "[[454, 237, 11, 12], [459, 266, 9, 12]] (240, 300)\n",
      "[[454, 237, 11, 12], [459, 266, 9, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 87.6ms\n",
      "Speed: 1.8ms preprocess, 87.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 12]] (240, 240)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 12]] (240, 270)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 12]] (240, 300)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 2 screws, 105.5ms\n",
      "Speed: 2.0ms preprocess, 105.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 240)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 270)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 300)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 1 center, 1 screw, 100.0ms\n",
      "Speed: 2.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[454, 237, 11, 12]] (240, 240)\n",
      "[[454, 237, 11, 12]] (240, 270)\n",
      "[[454, 237, 11, 12]] (240, 300)\n",
      "[[454, 237, 11, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 1 center, 1 screw, 117.8ms\n",
      "Speed: 4.0ms preprocess, 117.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 237, 11, 12]] (240, 240)\n",
      "[[455, 237, 11, 12]] (240, 270)\n",
      "[[455, 237, 11, 12]] (240, 300)\n",
      "[[455, 237, 11, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 94.1ms\n",
      "Speed: 2.4ms preprocess, 94.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 13]] (240, 240)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 13]] (240, 270)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 13]] (240, 300)\n",
      "[[455, 237, 11, 12], [459, 266, 9, 13]] (240, 330)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 122.1ms\n",
      "Speed: 4.0ms preprocess, 122.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 240)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 270)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 300)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 12]] (240, 330)\n",
      "\n",
      "0: 480x640 1 center, 2 screws, 95.2ms\n",
      "Speed: 1.7ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 13]] (240, 240)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 13]] (240, 270)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 13]] (240, 300)\n",
      "[[455, 237, 10, 12], [459, 266, 9, 13]] (240, 330)\n",
      "[False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"DetectionWeights.pt\")\n",
    "cam_url = 'http://192.168.107.228/capture'\n",
    "print(check_screws(positions, 2, cam_url, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
